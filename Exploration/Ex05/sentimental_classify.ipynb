{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2957d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e60ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def tokenize_and_remove_stopwords(text):\n",
    "    tokens = tokenizer.morphs(text)\n",
    "    tokens = [t for t in tokens if t not in stopwords]\n",
    "    return tokens\n",
    "\n",
    "def load_data(train_data, test_data, num_words):\n",
    "    train_data.drop_duplicates(inplace=True)\n",
    "    test_data.drop_duplicates(inplace=True)\n",
    "    train_data.dropna(how='any',inplace=True)\n",
    "    test_data.dropna(how='any', inplace=True)\n",
    "    train_data.reset_index(inplace=True, drop=True)\n",
    "    test_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    token_list=[]\n",
    "    for sentence in train_data['document']:\n",
    "        token_list.extend(tokenize_and_remove_stopwords(sentence))\n",
    "\n",
    "    word_counts = Counter(token_list)\n",
    "    word_to_index = {word: idx + 3 for idx, (word, _) in enumerate(word_counts.most_common(num_words-3))}\n",
    "    word_to_index['<PAD>'] = 0\n",
    "    word_to_index['<UNK>'] = 1\n",
    "    word_to_index['<BOS>'] = 2\n",
    "\n",
    "    train_data['tokens']=train_data['document'].apply(tokenize_and_remove_stopwords)\n",
    "    test_data['tokens']=test_data['document'].apply(tokenize_and_remove_stopwords)\n",
    "    train_data['sequence']=train_data['tokens'].apply(lambda x : [word_to_index['<BOS>']]+[word_to_index.get(i,word_to_index['<UNK>']) for i in x])\n",
    "    test_data['sequence']=test_data['tokens'].apply(lambda x : [word_to_index['<BOS>']]+[word_to_index.get(i,word_to_index['<UNK>']) for i in x])\n",
    "    \n",
    "    return list(train_data['sequence']), np.array(list(train_data['label'])), list(test_data['sequence']), np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data,20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83a01bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in tokenizer.morphs(sentence)]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7af374c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71e3e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "872b0d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  16.65940637625505\n",
      "문장길이 최대 :  117\n",
      "문장길이 표준편차 :  12.859527414389605\n",
      "pad_sequences maxlen :  42\n",
      "전체 문장의 0.9358074322972919%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d07c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='pre',\n",
    "                                                       maxlen=42)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='pre',\n",
    "                                                       maxlen=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46a92258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 40)          800000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 328       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 800,337\n",
      "Trainable params: 800,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index) # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 40   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model1 = tf.keras.Sequential()\n",
    "model1.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model1.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model1.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model1.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "358ed405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 40)          800000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          4496      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 806,449\n",
      "Trainable params: 806,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 40   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model2 = tf.keras.Sequential()\n",
    "model2.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model2.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model2.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model2.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model2.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model2.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model2.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4dea4435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 40)          800000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 1568      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 801,649\n",
      "Trainable params: 801,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 40  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model3 = tf.keras.Sequential()\n",
    "model3.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model3.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model3.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model3.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "523d8cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149995"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c16adad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119996, 42)\n",
      "(119996,)\n"
     ]
    }
   ],
   "source": [
    "idx=round(0.2*len(x_train))\n",
    "          \n",
    "x_val = x_train[:idx]   \n",
    "y_val = y_train[:idx]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[idx:]  \n",
    "partial_y_train = y_train[idx:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6a67eb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "235/235 [==============================] - 2s 4ms/step - loss: 0.5579 - accuracy: 0.7520 - val_loss: 0.3947 - val_accuracy: 0.8330\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3469 - accuracy: 0.8550 - val_loss: 0.3416 - val_accuracy: 0.8499\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2915 - accuracy: 0.8807 - val_loss: 0.3356 - val_accuracy: 0.8549\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2552 - accuracy: 0.8980 - val_loss: 0.3416 - val_accuracy: 0.8548\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2249 - accuracy: 0.9120 - val_loss: 0.3528 - val_accuracy: 0.8543\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1983 - accuracy: 0.9248 - val_loss: 0.3714 - val_accuracy: 0.8517\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1743 - accuracy: 0.9353 - val_loss: 0.3908 - val_accuracy: 0.8482\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1527 - accuracy: 0.9460 - val_loss: 0.4176 - val_accuracy: 0.8462\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1338 - accuracy: 0.9538 - val_loss: 0.4437 - val_accuracy: 0.8438\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1169 - accuracy: 0.9612 - val_loss: 0.4719 - val_accuracy: 0.8415\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1021 - accuracy: 0.9669 - val_loss: 0.5018 - val_accuracy: 0.8378\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0891 - accuracy: 0.9722 - val_loss: 0.5343 - val_accuracy: 0.8351\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0785 - accuracy: 0.9758 - val_loss: 0.5664 - val_accuracy: 0.8355\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0690 - accuracy: 0.9795 - val_loss: 0.5992 - val_accuracy: 0.8315\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0613 - accuracy: 0.9823 - val_loss: 0.6335 - val_accuracy: 0.8289\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0545 - accuracy: 0.9847 - val_loss: 0.6601 - val_accuracy: 0.8287\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0491 - accuracy: 0.9860 - val_loss: 0.6947 - val_accuracy: 0.8264\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0442 - accuracy: 0.9876 - val_loss: 0.7326 - val_accuracy: 0.8243\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0401 - accuracy: 0.9889 - val_loss: 0.7600 - val_accuracy: 0.8231\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9901 - val_loss: 0.7893 - val_accuracy: 0.8227\n"
     ]
    }
   ],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history1 = model1.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "187aa37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "235/235 [==============================] - 4s 6ms/step - loss: 0.4790 - accuracy: 0.7613 - val_loss: 0.3616 - val_accuracy: 0.8388\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3199 - accuracy: 0.8634 - val_loss: 0.3491 - val_accuracy: 0.8435\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2624 - accuracy: 0.8928 - val_loss: 0.3581 - val_accuracy: 0.8447\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9197 - val_loss: 0.3989 - val_accuracy: 0.8391\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1537 - accuracy: 0.9434 - val_loss: 0.4449 - val_accuracy: 0.8353\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1139 - accuracy: 0.9598 - val_loss: 0.4976 - val_accuracy: 0.8321\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0868 - accuracy: 0.9691 - val_loss: 0.5558 - val_accuracy: 0.8270\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0681 - accuracy: 0.9752 - val_loss: 0.6154 - val_accuracy: 0.8251\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0571 - accuracy: 0.9790 - val_loss: 0.6736 - val_accuracy: 0.8232\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9811 - val_loss: 0.7368 - val_accuracy: 0.8182\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0428 - accuracy: 0.9833 - val_loss: 0.7803 - val_accuracy: 0.8196\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0389 - accuracy: 0.9845 - val_loss: 0.8763 - val_accuracy: 0.8179\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0363 - accuracy: 0.9848 - val_loss: 0.8792 - val_accuracy: 0.8173\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0335 - accuracy: 0.9860 - val_loss: 0.9491 - val_accuracy: 0.8147\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0320 - accuracy: 0.9864 - val_loss: 0.9947 - val_accuracy: 0.8154\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9860 - val_loss: 1.0448 - val_accuracy: 0.8146\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0319 - accuracy: 0.9857 - val_loss: 1.0860 - val_accuracy: 0.8115\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0336 - accuracy: 0.9851 - val_loss: 1.1373 - val_accuracy: 0.8145\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0383 - accuracy: 0.9829 - val_loss: 1.1449 - val_accuracy: 0.8127\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0345 - accuracy: 0.9847 - val_loss: 1.1427 - val_accuracy: 0.8161\n"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history2 = model2.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0eeebccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "235/235 [==============================] - 3s 7ms/step - loss: 0.4938 - accuracy: 0.7714 - val_loss: 0.3591 - val_accuracy: 0.8471\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3285 - accuracy: 0.8641 - val_loss: 0.3430 - val_accuracy: 0.8538\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.2970 - accuracy: 0.8791 - val_loss: 0.3451 - val_accuracy: 0.8535\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.2768 - accuracy: 0.8892 - val_loss: 0.3509 - val_accuracy: 0.8522\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.2623 - accuracy: 0.8959 - val_loss: 0.3612 - val_accuracy: 0.8495\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.2471 - accuracy: 0.9027 - val_loss: 0.3766 - val_accuracy: 0.8482\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.2330 - accuracy: 0.9083 - val_loss: 0.3856 - val_accuracy: 0.8485\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.2195 - accuracy: 0.9132 - val_loss: 0.4051 - val_accuracy: 0.8472\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.2070 - accuracy: 0.9178 - val_loss: 0.4129 - val_accuracy: 0.8468\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1959 - accuracy: 0.9220 - val_loss: 0.4555 - val_accuracy: 0.8457\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1856 - accuracy: 0.9252 - val_loss: 0.4691 - val_accuracy: 0.8432\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1757 - accuracy: 0.9293 - val_loss: 0.4837 - val_accuracy: 0.8426\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1658 - accuracy: 0.9327 - val_loss: 0.5168 - val_accuracy: 0.8436\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1591 - accuracy: 0.9355 - val_loss: 0.5475 - val_accuracy: 0.8424\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1513 - accuracy: 0.9378 - val_loss: 0.5769 - val_accuracy: 0.8422\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1454 - accuracy: 0.9401 - val_loss: 0.5886 - val_accuracy: 0.8405\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1403 - accuracy: 0.9414 - val_loss: 0.6214 - val_accuracy: 0.8393\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1354 - accuracy: 0.9449 - val_loss: 0.6154 - val_accuracy: 0.8386\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1265 - accuracy: 0.9485 - val_loss: 0.6651 - val_accuracy: 0.8388\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1223 - accuracy: 0.9502 - val_loss: 0.6869 - val_accuracy: 0.8363\n"
     ]
    }
   ],
   "source": [
    "model3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history3 = model3.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c8778b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history1.history\n",
    "history_dict2 = history2.history\n",
    "history_dict3 = history3.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0957f9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyLUlEQVR4nO3dd5hU5fn/8fcNgoiAomBjqRE09LIgihKMJkEwgEYNuFGIhUDsxkKCUYLyMypRQoKJWLBhwBglGCEYFQSDhQURReErImWxIUoLKO3+/fGchWHZBrtnZ3bm87quuXbmzCn3np0995ynmrsjIiKZq0qyAxARkeRSIhARyXBKBCIiGU6JQEQkwykRiIhkOCUCEZEMp0Qg5crMppvZwPJeN5nMbIWZnRnDft3Mjo+e/9XMfluadQ/gODlm9uKBxlnMfnuYWV5571cq3kHJDkCSz8w2J7ysCXwL7Ixe/8LdJ5Z2X+5+Vhzrpjt3H1Ie+zGzJsDHQDV33xHteyJQ6r+hZB4lAsHda+U/N7MVwGXu/lLB9czsoPyLi4ikDxUNSZHyb/3N7GYz+wyYYGZ1zexfZrbWzL6OnmclbDPLzC6Lng8ys9fMbHS07sdmdtYBrtvUzGab2SYze8nMxpnZk0XEXZoYbzez/0b7e9HM6iW8f5GZrTSzdWY2vJjzc5KZfWZmVROWnWNmi6LnXczsdTNbb2afmtmfzax6Eft61MzuSHh9Y7TNJ2Z2SYF1e5vZ22a20cxWm9mIhLdnRz/Xm9lmMzs5/9wmbH+Kmc0zsw3Rz1NKe26KY2bfjbZfb2aLzaxPwnu9zOz9aJ9rzOyGaHm96O+z3sy+MrM5ZqbrUgXTCZeSHAMcATQGBhM+MxOi142ArcCfi9n+JGApUA+4G3jYzOwA1n0KeAs4EhgBXFTMMUsT44XAz4GjgOpA/oWpJfCXaP/HRcfLohDu/ibwP+D7Bfb7VPR8J3Bd9PucDJwB/LKYuIli6BnF8wOgOVCwfuJ/wMXA4UBvYKiZ9Yve6x79PNzda7n76wX2fQTwAjA2+t3uBV4wsyML/A77nJsSYq4GPA+8GG13FTDRzE6IVnmYUMxYG2gNvBIt/xWQB9QHjgZ+A2jcmwqmRCAl2QXc5u7fuvtWd1/n7v9w9y3uvgkYBXyvmO1XuvuD7r4TeAw4lvAPX+p1zawR0Bm41d23uftrwNSiDljKGCe4+/+5+1bgaaB9tPw84F/uPtvdvwV+G52DovwNGABgZrWBXtEy3H2+u7/h7jvcfQXwQCFxFOaCKL733P1/hMSX+PvNcvd33X2Xuy+Kjlea/UJIHB+6+xNRXH8DlgA/TlinqHNTnK5ALeD30d/oFeBfROcG2A60NLM67v61uy9IWH4s0Njdt7v7HNcAaBVOiUBKstbdv8l/YWY1zeyBqOhkI6Eo4vDE4pECPst/4u5boqe19nPd44CvEpYBrC4q4FLG+FnC8y0JMR2XuO/oQryuqGMRvv2fa2YHA+cCC9x9ZRRHi6jY47Mojv9HuDsoyV4xACsL/H4nmdnMqOhrAzCklPvN3/fKAstWAg0SXhd1bkqM2d0Tk2bifn9CSJIrzexVMzs5Wn4PsAx40cyWm9mw0v0aUp6UCKQkBb+d/Qo4ATjJ3euwpyiiqOKe8vApcISZ1UxY1rCY9csS46eJ+46OeWRRK7v7+4QL3lnsXSwEoYhpCdA8iuM3BxIDoXgr0VOEO6KG7n4Y8NeE/Zb0bfoTQpFZokbAmlLEVdJ+GxYo39+9X3ef5+59CcVGUwh3Grj7Jnf/lbs3A/oA15vZGWWMRfaTEoHsr9qEMvf1UXnzbXEfMPqGnQuMMLPq0bfJHxezSVlifAY428xOjSp2R1Ly/8lTwDWEhPP3AnFsBDab2YnA0FLG8DQwyMxaRomoYPy1CXdI35hZF0ICyreWUJTVrIh9TwNamNmFZnaQmf0UaEkoximLNwl3DzeZWTUz60H4G02K/mY5ZnaYu28nnJNdAGZ2tpkdH9UFbSDUqxRXFCcxUCKQ/TUGOAT4EngD+HcFHTeHUOG6DrgDmEzo71CYMRxgjO6+GLiCcHH/FPiaUJlZnPwy+lfc/cuE5TcQLtKbgAejmEsTw/Tod3iFUGzySoFVfgmMNLNNwK1E366jbbcQ6kT+G7XE6Vpg3+uAswl3TeuAm4CzC8S939x9G+HCfxbhvN8PXOzuS6JVLgJWREVkQwh/TwiV4S8Bm4HXgfvdfWZZYpH9Z6qXkcrIzCYDS9w99jsSkXSnOwKpFMyss5l9x8yqRM0r+xLKmkWkjNSzWCqLY4BnCRW3ecBQd387uSGJpAcVDYmIZDgVDYmIZLhKVzRUr149b9KkSbLDEBGpVObPn/+lu9cv7L1KlwiaNGlCbm5ussMQEalUzKxgj/LdVDQkIpLhlAhERDJcrInAzHqa2VIzW1bYYFJm1igaPOttM1tkZr3ijEdERPYVWx1BNNLjOMKY6nnAPDObGg3Sle8W4Gl3/0s0Dvw0oMn+Hmv79u3k5eXxzTfflLyyJFWNGjXIysqiWrVqyQ5FRCJxVhZ3AZa5+3IAM5tE6A2amAgcqBM9P4wwguF+y8vLo3bt2jRp0oSi5zyRZHN31q1bR15eHk2bNk12OCISibNoqAF7j6mex95jnkOYcONnZpZHuBu4qrAdmdlgM8s1s9y1a9fu8/4333zDkUceqSSQ4syMI488UnduIikm2ZXFA4BH3T2LMGnFE4XNV+ru4909292z69cvtBmskkAlob+TSOqJMxGsYe/JNbLYd/KLS9kzQcXrQA1KP9OSiEhGWLsWhg+HDz+MZ/9xJoJ5QHMzaxpN8NGffeeZXUWY0Bsz+y4hEexb9pPi1q1bR/v27Wnfvj3HHHMMDRo02P1627ZtxW6bm5vL1VdfXeIxTjnllHKJddasWZx99tnlsi8Ridcnn8D110OTJnDnnfDSS/EcJ7bKYnffYWZXAjOAqsAj7r7YzEYCue4+lTA5xoNmdh2h4nhQRUxcPXFiyK6rVkGjRjBqFOTklLxdUY488kgWLlwIwIgRI6hVqxY33HDD7vd37NjBQQcVfqqzs7PJzs4u8Rhz58498ABFpFL5+GO46y6YMAF27gzXp2HD4Lvfjed4sdYRuPs0d2/h7t9x91HRslujJIC7v+/u3dy9nbu3d/cX44wHQhIYPBhWrgT38HPw4LC8PA0aNIghQ4Zw0kkncdNNN/HWW29x8skn06FDB0455RSWLl0K7P0NfcSIEVxyySX06NGDZs2aMXbs2N37q1Wr1u71e/TowXnnnceJJ55ITk4O+blz2rRpnHjiiXTq1Imrr766xG/+X331Ff369aNt27Z07dqVRYsWAfDqq6/uvqPp0KEDmzZt4tNPP6V79+60b9+e1q1bM2fOnPI9YSLCBx/AxRdD8+YhCVxySSgOeuyx+JIAVMKxhspq+HDYsmXvZVu2hOVluSsoTF5eHnPnzqVq1aps3LiROXPmcNBBB/HSSy/xm9/8hn/84x/7bLNkyRJmzpzJpk2bOOGEExg6dOg+be7ffvttFi9ezHHHHUe3bt3473//S3Z2Nr/4xS+YPXs2TZs2ZcCAASXGd9ttt9GhQwemTJnCK6+8wsUXX8zChQsZPXo048aNo1u3bmzevJkaNWowfvx4fvSjHzF8+HB27tzJloInUUQO2Ntvh5KJZ5+FQw6Ba66BX/0KjjuuYo6fcYlg1ar9W14W559/PlWrVgVgw4YNDBw4kA8//BAzY/v27YVu07t3bw4++GAOPvhgjjrqKD7//HOysrL2WqdLly67l7Vv354VK1ZQq1YtmjVrtrt9/oABAxg/fnyx8b322mu7k9H3v/991q1bx8aNG+nWrRvXX389OTk5nHvuuWRlZdG5c2cuueQStm/fTr9+/Wjfvn1ZTo2IAP/9b0gA06dDnTrwm9/AtddCvQpuMpPs5qMVrlGj/VteFoceeuju57/97W85/fTTee+993j++eeLbEt/8MEH735etWpVduzYcUDrlMWwYcN46KGH2Lp1K926dWPJkiV0796d2bNn06BBAwYNGsTjjz9erscUyRTu8J//QI8ecOqpMG9eSAarVsEdd1R8EoAMTASjRkHNmnsvq1kzLI/Thg0baNAg9Kd79NFHy33/J5xwAsuXL2fFihUATJ48ucRtTjvtNCZGlSOzZs2iXr161KlTh48++og2bdpw880307lzZ5YsWcLKlSs5+uijufzyy7nssstYsGBBuf8OIuls1y6YOhW6doUf/jCU/d93H6xYEe4EDjssebFlXCLIyYHx46FxYzALP8ePL//6gYJuuukmfv3rX9OhQ4dy/wYPcMghh3D//ffTs2dPOnXqRO3atTmshE/WiBEjmD9/Pm3btmXYsGE89thjAIwZM4bWrVvTtm1bqlWrxllnncWsWbNo164dHTp0YPLkyVxzzTXl/juIpKNt20Jlb/v20Ldv6BPwwAOwfHkoBkooOEiaSjdncXZ2thecmOaDDz7gu3FWqVcSmzdvplatWrg7V1xxBc2bN+e6665Ldlj70N9LMsFXX4UL/p/+BJ9+Cq1ahSag/ftDEa3JY2Vm89290LbqGXdHkM4efPBB2rdvT6tWrdiwYQO/+MUvkh2SSMb56CO46ipo2DAU+bRuDf/+N7z7LvzsZ8lJAiVJwZDkQF133XUpeQcgkgnmzoU//AGeey5c7C+8MPQKbts22ZGVTIlAROQA7dwZLvx/+AO88QbUrRuKf668suL6AJQHJQIRkf20eTM88giMGROGg2jWLNQF/PznqVH5u7+UCERESmnNmnDBf+ABWL8eTjkFRo8OrYGivqOVkhKBiEgJ1qwJw9A89VQoDjr33DAERNeuyY6sfKjVUDk4/fTTmTFjxl7LxowZw9ChQ4vcpkePHuQ3g+3Vqxfr16/fZ50RI0YwevToYo89ZcoU3n9/z+yft956Ky+Vw1i1Gq5aJFz0//hHOPFEmDwZhg4NHcH+/vf0SQKgRFAuBgwYwKRJk/ZaNmnSpFIN/AZh1NDDDz/8gI5dMBGMHDmSM88884D2JSJ75OZCly6h01e3bvDeeyEpNGuW7MjKnxJBOTjvvPN44YUXdk9Cs2LFCj755BNOO+00hg4dSnZ2Nq1ateK2224rdPsmTZrw5ZdfAjBq1ChatGjBqaeeunuoagh9BDp37ky7du34yU9+wpYtW5g7dy5Tp07lxhtvpH379nz00UcMGjSIZ555BoCXX36ZDh060KZNGy655BK+/fbb3ce77bbb6NixI23atGHJkiXF/n4arloyyYYNoR9Aly5hYpjJk8OgcN/5TrIji0/a1RFcey1Ec8SUm/btQ+uAohxxxBF06dKF6dOn07dvXyZNmsQFF1yAmTFq1CiOOOIIdu7cyRlnnMGiRYtoW0TD4vnz5zNp0iQWLlzIjh076NixI506dQLg3HPP5fLLLwfglltu4eGHH+aqq66iT58+nH322Zx33nl77eubb75h0KBBvPzyy7Ro0YKLL76Yv/zlL1x77bUA1KtXjwULFnD//fczevRoHnrooSJ/Pw1XLZnAHZ55JgwB/dlncMUVYRC4ZI4BVFF0R1BOEouHEouFnn76aTp27EiHDh1YvHjxXsU4Bc2ZM4dzzjmHmjVrUqdOHfr06bP7vffee4/TTjuNNm3aMHHiRBYvXlxsPEuXLqVp06a0aNECgIEDBzJ79uzd75977rkAdOrUafdAdUV57bXXuOiii4DCh6seO3Ys69ev56CDDqJz585MmDCBESNG8O6771K7du1i9y2SCpYvh9694YIL4Jhj4M03Q+ugTEgCkIZ3BMV9c49T3759ue6661iwYAFbtmyhU6dOfPzxx4wePZp58+ZRt25dBg0aVOTw0yUZNGgQU6ZMoV27djz66KPMmjWrTPHmD2VdlmGshw0bRu/evZk2bRrdunVjxowZu4erfuGFFxg0aBDXX389F198cZliFYnLtm2hM9jIkaE38Jgx4U4gFYeBiFOsdwRm1tPMlprZMjMbVsj795nZwujxf2a2Ps544lSrVi1OP/10Lrnkkt13Axs3buTQQw/lsMMO4/PPP2f69OnF7qN79+5MmTKFrVu3smnTJp5//vnd723atIljjz2W7du37x46GqB27dps2rRpn32dcMIJrFixgmXLlgHwxBNP8L3vfe+AfjcNVy3p6LXXoEOHMB5Qr15hmshrrsm8JAAx3hGYWVVgHPADIA+YZ2ZT3X132Yi7X5ew/lVAh7jiqQgDBgzgnHPO2V1ElD9s84knnkjDhg3p1q1bsdt37NiRn/70p7Rr146jjjqKzp07737v9ttv56STTqJ+/fqcdNJJuy/+/fv35/LLL2fs2LG7K4kBatSowYQJEzj//PPZsWMHnTt3ZsiQIQf0e+XPpdy2bVtq1qy513DVM2fOpEqVKrRq1YqzzjqLSZMmcc8991CtWjVq1aqlCWwk5axbBzffDA8/HIahf/55yPSW0rENQ21mJwMj3P1H0etfA7j7nUWsPxe4zd3/U9x+NQx15ae/lySDOzz+ONxwQ+gVfP31cOutlXNIiAORrGGoGwCrE17nRcv2YWaNgabAK0W8P9jMcs0sd+3ateUeqIikt0WL4PTTYdAgaNECFiyAu+7KnCRQklRpNdQfeMbddxb2pruPd/dsd8+uX79+BYcmIpXV55/D4MGhLuDdd8NshHPmQJs2yY4stcSZCNYADRNeZ0XLCtMf+FtZDlbZZlrLVPo7SUX45pvwjb95c5gwAa6+GpYtg8svhyqp8vU3hcR5SuYBzc2sqZlVJ1zspxZcycxOBOoCrx/ogWrUqMG6det0kUlx7s66deuoUaNGskORNJXfKaxlyzAvQI8esHhxmCS+bt1kR5e6Yms15O47zOxKYAZQFXjE3Reb2Ugg193zk0J/YJKX4SqelZVFXl4eqj9IfTVq1CArKyvZYUgamj8frrtuT9HPSy/BGWckO6rKIS0mrxeRzPXJJ6EvwOOPQ716YViISy+t3PMDxKG4VkMZ2HVCRNLBli2hV/Dvfw87dsCNN4aEkCnDQpQnJQIRqVTc4W9/C53C8vLgvPNCxXA6Dg9dUVR/LiKVxhtvwMknQ04OHHUUvPpqmCRGSaBslAhEJOUtWgQDBoQksGpVaBI6bx50757syNKDioZEJCXt3BnGAfrjH2HWLKhZE265JRQJ1aqV7OjSixKBiKSUDRvgkUfCfAAffwyNGsHdd8Nll6kvQFyUCEQkJXz4Ybj4T5gAmzfDqaeGBNCvX2YODV2RdHpFJGnc4eWXw4Qw06aFC37//mFegGiWVqkASgQiUuG2bIEnn4SxY8MQEEcdFYaEHjIkTBUpFUuJQEQqTF4ejBsXRgH96qswKuijj4a7gGj2VEkCJQIRid3SpXDbbWFAOPdQ7n/ttaEewCzZ0YkSgYjEZt26MDH8/ffDIYeEQeGuuAKaNEl2ZJJIiUBEyt22baEIaORI2LgxTA7zu9+FugBJPUoEIlJu3OGf/wwDwC1bBj/8YRgYrnXrZEcmxdEQEyJSLhYsCPMCn3MOVK8O06fDjBlKApWBEoGIlMmaNWFS+Ozs0BT0/vvhnXegZ89kRyalpaIhETkg//sf3HNPeGg+gMot1jsCM+tpZkvNbJmZDStinQvM7H0zW2xmT8UZj4iU3a5doe1/ixahAvjss2HJkjAngJJA5RTbHYGZVQXGAT8A8oB5ZjbV3d9PWKc58Gugm7t/bWZqUyCSwmbNguuvh7ffhi5d4OmnoVu3ZEclZRXnHUEXYJm7L3f3bcAkoG+BdS4Hxrn71wDu/kWM8YjIAVqyJFQCn346fPklTJwIr7+uJJAu4kwEDYDVCa/zomWJWgAtzOy/ZvaGmRVavWRmg80s18xy165dG1O4IlLQmjWhD0Dr1vDSSzBqVOglfOGFUEVNTdJGsiuLDwKaAz2ALGC2mbVx9/WJK7n7eGA8QHZ2tldwjCIZ5+uvQ5n/H/8YJoi54goYPlwdwtJVnIlgDdAw4XVWtCxRHvCmu28HPjaz/yMkhnkxxiUiRdi6Ff78Z7jzTli/PnzzHzlScwKnuzhv7uYBzc2sqZlVB/oDUwusM4VwN4CZ1SMUFS2PMSYRKcSOHWFWsBYt4KaboGvXUCH85JNKApkgtkTg7juAK4EZwAfA0+6+2MxGmlmfaLUZwDozex+YCdzo7uviiklE9pY/JETbtnDppXDccTBzZpgkpl27ZEcnFcXcK1eRe3Z2tufm5iY7DJFKb84cGDYM5s4NdwJ33hlaBmlY6PRkZvPdPbuw91TvL5Jh3n0Xfvxj6N49TA4/fnwYGuLcc5UEMpUSgUiGWLkSBg4MRT5z5oQ7gGXL4PLLNTl8psuIRDBxYpgIo0qV8HPixGRHJFJxvvgiTAjTogVMngw33ADLl4dioZo1kx2dpIK0/x4wcWLoELNlS3i9cmV4DZCTk7y4ROK2YQOMHg333ReahQ4aBCNGQMOGJW0pmSbt7wiGD9+TBPJt2RKWi6SjLVvCiKDNmsEdd0Dv3vD++/Dww0oCUri0TwSrVu3fcpHKavt2+Otf4fjjQ1+Ak06C+fNDcdAJJyQ7OkllaZ8IGjXav+Uilc3OnaEI9MQTYejQcCcwe3boC9CxY7Kjk8og7RPBqFH7VojVrBmWi1Rm+Z3B2reHn/0M6tSBF14ILYJOOy3Z0UllkvaJICcntJNu3Di0kW7cOLxWRbFUZjNnwimnQL9+8O23MGlSKAbq1Ut9AWT/pX2rIQgXfV34JR3Mmxemg3zpJcjKggcfDK2B1A9AyiLt7whE0sEHH4Sev126wMKFcO+98OGHcNllSgJSdvoIiaSw1avhttvgscfg0EPDHMHXXQe1ayc7MkknSgQiKWjdOvh//w/GjQuVwtdeC7/+NdSrl+zIJB0pEYikkM2bYcyY0CFs8+YwNtCIEWruLPFSIhBJAdu2hYrf22+Hzz8PrYHuuANatUp2ZJIJlAhEkmjXrtD087e/DQPBde8Ozz0HJ5+c7Mgkk6jVkEgSuMP06aHnb05OqPydPh1mzVISkIoXayIws55mttTMlpnZsELeH2Rma81sYfS4LM54RFLB669Djx6h89emTfDUU7BgAfTsqc5gkhyxFQ2ZWVVgHPADIA+YZ2ZT3f39AqtOdvcr44pDJFUsXhxGvf3nP+Hoo0OLoMsug+rVkx2ZZLo47wi6AMvcfbm7bwMmAX1jPJ5ISlq8GC68MEwQP3NmqAT+6CP45S+VBCQ1xJkIGgCrE17nRcsK+omZLTKzZ8ys0NHSzWywmeWaWe7atWvjiFWk3L3zDpx/PrRuDVOn7pkZbPjw0DlMJFUku7L4eaCJu7cF/gM8VthK7j7e3bPdPbt+/foVGqDI/po/PzT/bN8eXnwRbrklzIx3111w5JHJjk5kX3EmgjVA4jf8rGjZbu6+zt2/jV4+BHSKMR6RWL3xRpgNLDs7zAfwu9+FBHD77UoAktriTATzgOZm1tTMqgP9gamJK5jZsQkv+wAfxBiPSCzmzIEf/CA0+3zzzTA0xIoVcOutcPjhyY5OpGSxtRpy9x1mdiUwA6gKPOLui81sJJDr7lOBq82sD7AD+AoYFFc8IuXJPVT8jhwJr74KRx0VhoUYMgRq1Up2dCL7x9w92THsl+zsbM/NzU12GJKh3EO5/8iRMHcuHHss3HwzXH75vjPhiaQSM5vv7tmFvZfsymKRSsEdnn8+TAjfs2cYHnrcuNAK6JprlASkctNYQyLF2L4d/va3UOzz3nvQtGmY6nTgQPUBkPShRCBSiE2b4KGH4L77wrf/Vq3C5DADBkC1asmOTqR8KRGIJPj8cxg7Fu6/H9avh+99D/76VzjrLI0DJOlLiUCEMP/v6NHhW/+2bWF+4BtvDHUCIulOiUAy2ltvwd13w7PPhjL/gQPDUBDNmyc7MpGKo0QgGSd/LoC77w59AA4/PMwHfNVVcMwxyY5OpOIpEUjGKNgCKCsL7r03DAVdu3ayoxNJHiUCSXvr1sHDD8Of/xxaALVuDY8/Dv37qwWQCJQyEZjZocBWd99lZi2AE4Hp7r491uhEymDRIvjTn+DJJ+Gbb+D009UCSKQwpb0jmA2cZmZ1gRcJA8r9FMiJKzCRA7FjRxj7/09/CvP/HnIIXHRRKP9v0ybZ0YmkptImAnP3LWZ2KXC/u99tZgtjjEtkv3z1VegANm4crFoFjRqFyuBLL4Ujjkh2dCKprdSJwMxOJtwBXBotqxpPSCKl9+67e4p/tm4NxT9jxsCPfwwHqQZMpFRK+69yLfBr4LloKOlmwMzYohIpxs6dofhn7Ng9xT8/+5mKf0QOVKkSgbu/CrwKYGZVgC/d/eo4AxMp6KuvQuufcePCzF+NGoXpHy+9VDOAiZRFqYahNrOnzKxO1HroPeB9M7sx3tBEgg8+CBO+ZGXBTTeFEUCffRY++ii8VhIQKZvSzkfQ0t03Av2A6UBT4KK4ghJxhxkzQlPPli3h0UfhwgvhnXfCzGDnnKM6AJHyUtpEUM3MqhESwdSo/0CJU5uZWU8zW2pmy8xsWDHr/cTM3MwKnT1HMseWLfDAA2HY5549YeHCMPn76tWhVVDbtsmOUCT9lPY71QPACuAdYLaZNQY2FreBmVUFxgE/APKAeWY21d3fL7BebeAa4M39C13SyZo1oez/gQdCXUDHjvDEE3DBBZoARiRupbojcPex7t7A3Xt5sBI4vYTNugDL3H25u28DJgF9C1nvduAu4Jv9CVzSw7x5kJMDTZrA738fxv+fPRtyc0NLICUBkfiVtrL4MDO718xyo8cfgENL2KwBsDrhdV60LHG/HYGG7v5CCccfnH/stWvXlibkQq1ff8CbSjnasQOeeQZOPRW6dAlzAV91FSxbFiqBTztNQ0CIVKTS1hE8AmwCLogeG4EJZTlw1Az1XuBXJa3r7uPdPdvds+vXr39Axxs3Lgw29s47B7S5lIP16+EPf4Djj4fzz4dPPgmdv/LywiigzZolO0KRzFTaRPAdd78tKuZZ7u6/A0r6t10DNEx4nRUty1cbaA3MMrMVQFdgalwVxqedtufnjBlxHEEKs3kz/P3vYa7frKww6UuTJvDcc2FWsGuugTp1kh2lSGYrbSLYaman5r8ws27A1hK2mQc0N7OmZlYd6A9MzX/T3Te4ez13b+LuTYA3gD7unrtfv0EptW0Lb74ZvnX27h06Jkk8vvwSJkwIwzzUqxcqfF96KSSD+fNDb+B+/aCqBikRSQmlbTU0BHjczA6LXn8NDCxuA3ffYWZXAjMI4xI9Eg1PMRLIdfepxW0fhwYNQkXkBReEyUg+/jg0TVR5dNmtXg1TpoRv+q++Crt2hZ6/Q4aE+X+7ddOFXyRVmXuJ3QH2rGxWB8DdN5rZte4+Jq7AipKdne25uWW7adi+HYYODXcFOTnh58EHl1OAGWTJknDhf+650PoHQuevc84Jj44dlWRFUoWZzXf3Qove96tvZtS7ON/1wJgyxJU01arBgw+GoQpuuSW0YX/2WahbN9mRpTb3ULSTf/H/4IOwvHNnuPPOcPE/4YTkxigi+68snfQr9Xc9Mxg+PFRc/vznoehi2rTwWvbYti0U9UydGh6rVoUinu7d4Ze/DGX9WVnJjlJEyqIsiaD0ZUopLCcn1B2ccw507Qr/+hdkZ/hAF19/DdOnhwv/9OmwcWMY6vnMM2HEiD2VwCKSHopNBGa2icIv+AYcEktESdCjB8ydC716hZ6tkyaFi10mWb48dOz65z9DhfrOnXDUUaG9f58+IQnUrJnsKEUkDsUmAnevXVGBJNt3vwuvvx4SQL9+YdKTK65IdlTx2bUrVPDmF/m8915Y3rIl3Hgj9O0bev1WKW0DYxGptPRvnuCYY0Ib99694corQ+enXbtg4sRQd1ClSvg5cWKSAz1AW7eGoq/Bg0NxWNeuYWKXevVCz94PP4TFi0PFb9euSgIimUIjuhdw6KGhRcy114bhEObMCfPibo26z61cGS6kEOoXUtXmzSHud97Z81i4MPwetWuHIZ779AnFYZrcXSSz7Vc/glRQHv0ISsMd7rsPflXESEiNG8OKFbGHUSL30JIn8YL/zjth9q78P22dOtCuXWjXn18Pon4TIpmluH4ESgQlKKpDlFkoNqpIW7eGsvzEC/6iRbBhw551jj8+DKfRrt2eR+PG6tglkunKrUNZJmrcOBQHFXTIIaEe4dhj933Ur79/5evffguffQafflr84/PP93zLP/TQcMEfMGDPBb9NG6hVq3x+bxHJHEoEJRg1KtQJbNmyZ1mVKnD44aHSuLA5DqpWhaOP3jdB1KkDX3yx7wX+q6/23UeVKqH5Zv62HTuGjltt2oSLfrNmqswVkfKhRFCC/Arh4cNDWXyjRiE55C/furX4b/OrV8Nbb8HateHbfPXqoXXSscdC8+ahh25hdxVHHaVB2kSkYqiOoIJs3w7/+x8cdpjK60Wk4qmOIAVUqxaKk0REUo1KmUVEMpwSgYhIhlMiEBHJcEoEIiIZLtZEYGY9zWypmS0zs2GFvD/EzN41s4Vm9pqZtYwzHhER2VdsicDMqgLjgLOAlsCAQi70T7l7G3dvD9wN3BtXPCIiUrg47wi6AMvcfbm7bwMmAX0TVygwB/KhpMmsZwWlyzDWIpKe4uxH0ABYnfA6Dzip4EpmdgVwPVAd+H5hOzKzwcBggEaNGpV7oHGaOHHvISoqyzDWIpI5kl5Z7O7j3P07wM3ALUWsM97ds909u379+hUbYBkNH773OEUQXg8fnpx4REQKijMRrAEaJrzOipYVZRLQL8Z4kmLVqv1bLiJS0eJMBPOA5mbW1MyqA/2BqYkrmFnzhJe9gQ9jjCcpiirJqmQlXCKSxmJLBO6+A7gSmAF8ADzt7ovNbKSZ9YlWu9LMFpvZQkI9wcC44kmWUaOgZs29l9WsGZaLiKSCWAedc/dpwLQCy25NeH5NnMdPBSUNYy0ikmwafbQC5OTowi8iqSvprYZERCS5lAgqAXVIE5E4qWgoxalDmojETXcEKU4d0kQkbkoEKU4d0kQkbkoEKU4d0kQkbkoEKU4d0kQkbkoEKS4nB8aPh8aNwSz8HD9eFcUiUn7UaqgSUIc0EYmT7ggygPohiEhxdEeQ5tQPQURKojuCNKd+CCJSEiWCNKd+CCJSEiWCNKd+CCJSEiWCNKd+CCJSEiWCNKd+CCJSklgTgZn1NLOlZrbMzIYV8v71Zva+mS0ys5fNrHGc8WSqnBxYsQJ27Qo/9zcJqPmpSHqLLRGYWVVgHHAW0BIYYGYtC6z2NpDt7m2BZ4C744pHDkx+89OVK8F9T/NTJQOR9BHnHUEXYJm7L3f3bcAkoG/iCu4+093zGze+AWTFGI8cADU/FUl/cSaCBsDqhNd50bKiXApML+wNMxtsZrlmlrt27dpyDFFKouanIukvJSqLzexnQDZwT2Hvu/t4d8929+z69etXbHAZTs1PRdJfnIlgDdAw4XVWtGwvZnYmMBzo4+7fxhiPHAA1PxVJf3EmgnlAczNrambVgf7A1MQVzKwD8AAhCXwRYyxygNT8VCT9xZYI3H0HcCUwA/gAeNrdF5vZSDPrE612D1AL+LuZLTSzqUXsTpJIzU9F0luso4+6+zRgWoFltyY8PzPO40vyafRTkdSXEpXFkr7U/FQk9SkRSKzU/FQk9SkRSKzU/FQk9SkRSKzKo/mpKptF4qVEILEqa/NTjXUkEj9z92THsF+ys7M9Nzc32WFIBWnSJFz8C2rcODRlFZHSMbP57p5d2Hu6I5CUpspmkfgpEUhKU2WzSPyUCCSlqbJZJH5KBJLSVNksEj9VFktaU2WzSKDKYslYqmwWKZkSgaQ1VTaLlEyJQNKaKptFSqZEIGlNlc0iJVNlsUgxVNks6UKVxSIHSJXNkgliTQRm1tPMlprZMjMbVsj73c1sgZntMLPz4oxF5ECUR2Wz6hgk1cWWCMysKjAOOAtoCQwws5YFVlsFDAKeiisOkbIoa2Wz6hikMojzjqALsMzdl7v7NmAS0DdxBXdf4e6LgF0xxiFywMpa2aypOqUyiDMRNABWJ7zOi5btNzMbbGa5Zpa7du3acglOpLRyckLF8K5d4WdpkwCUXx2DipckTpWistjdx7t7trtn169fP9nhiJRaedUxqHhJ4hRnIlgDNEx4nRUtE8kY5dGhTcVLErc4E8E8oLmZNTWz6kB/YGqMxxNJOWWtY4DyKV5S0ZIUJ9YOZWbWCxgDVAUecfdRZjYSyHX3qWbWGXgOqAt8A3zm7q2K26c6lEmmKWuntvyipcS7ipo19z8hSeWWtA5l7j7N3Vu4+3fcfVS07FZ3nxo9n+fuWe5+qLsfWVISEMlEZS1eKo+iJd1RpLdKUVksksnKWrxU1qIlVVanPyUCkUqgLE1Yy9pySXcU6U+JQCTNlbVoSXcU6U+JQCTNlbVoSXcU6U+JQCQDlKVoSXcU6U+JQESKpTuK9KdEICIlyvQ7inRPJEoEIhKryn5HkRGJxN0r1aNTp04uIpnjySfda9Z0D5fh8KhZMywvDbO9t81/mJVu+8aNC9++ceOKiT9/H40bh5gbN96/bfMRRnQo9LqqOwIRSWnJvqMoa9FUKtyRlEST14tIWivrWEtlHeupSpVwAS/ILNS5xH38PcfT5PUikqHKekdR1sruZN+RlIYSgYikvbK0eqrsiaQ0lAhEREpQmRNJaRxUfrsSEZHC5OQc+NwP+dsNHx6Kgxo1CkmgPOeSUCIQEUlxZUkkpaGiIRGRDBdrIjCznma21MyWmdmwQt4/2MwmR++/aWZN4oxHRET2FVsiMLOqwDjgLKAlMMDMWhZY7VLga3c/HrgPuCuueEREpHBx3hF0AZa5+3J33wZMAvoWWKcv8Fj0/BngDDOzGGMSEZEC4kwEDYDVCa/zomWFruPuO4ANwJEFd2Rmg80s18xy165dG1O4IiKZqVK0GnL38cB4ADNba2aFdLhOCfWAL5MdRDEUX9mkenyQ+jEqvrIpS3yNi3ojzkSwBmiY8DorWlbYOnlmdhBwGLCuuJ26e/3yDLI8mVluUWN5pALFVzapHh+kfoyKr2ziii/OoqF5QHMza2pm1YH+wNQC60wFBkbPzwNe8co2Cp6ISCUX2x2Bu+8wsyuBGUBV4BF3X2xmIwnjYk8FHgaeMLNlwFeEZCEiIhUo1joCd58GTCuw7NaE598A58cZQwUbn+wASqD4yibV44PUj1HxlU0s8VW6+QhERKR8aYgJEZEMp0QgIpLhlAj2k5k1NLOZZva+mS02s2sKWaeHmW0ws4XR49bC9hVjjCvM7N3o2PvM62nB2GiMp0Vm1rECYzsh4bwsNLONZnZtgXUq/PyZ2SNm9oWZvZew7Agz+4+ZfRj9rFvEtgOjdT40s4GFrRNDbPeY2ZLo7/ecmR1exLbFfhZijnGEma1J+Dv2KmLbYsckizG+yQmxrTCzhUVsG+s5LOqaUqGfv6Jmtdej8AdwLNAxel4b+D+gZYF1egD/SmKMK4B6xbzfC5gOGNAVeDNJcVYFPgMaJ/v8Ad2BjsB7CcvuBoZFz4cBdxWy3RHA8uhn3eh53QqI7YfAQdHzuwqLrTSfhZhjHAHcUIrPwEdAM6A68E7B/6e44ivw/h+AW5NxDou6plTk5093BPvJ3T919wXR803AB+w7dEaq6ws87sEbwOFmdmwS4jgD+Mjdk95T3N1nE5owJ0ocC+sxoF8hm/4I+I+7f+XuXwP/AXrGHZu7v+hhWBaANwgdNpOmiPNXGqUZk6zMiosvGt/sAuBv5X3c0ijmmlJhnz8lgjKIhs3uALxZyNsnm9k7ZjbdzFpVbGQ48KKZzTezwYW8X5pxoCpCf4r+50vm+ct3tLt/Gj3/DDi6kHVS4VxeQrjDK0xJn4W4XRkVXz1SRNFGKpy/04DP3f3DIt6vsHNY4JpSYZ8/JYIDZGa1gH8A17r7xgJvLyAUd7QD/gRMqeDwTnX3joQhwK8ws+4VfPwSRb3N+wB/L+TtZJ+/fXi4D0+5ttZmNhzYAUwsYpVkfhb+AnwHaA98Sih+SUUDKP5uoELOYXHXlLg/f0oEB8DMqhH+YBPd/dmC77v7RnffHD2fBlQzs3oVFZ+7r4l+fgE8R7j9TlSacaDidhawwN0/L/hGss9fgs/zi8yin18Usk7SzqWZDQLOBnKiC8U+SvFZiI27f+7uO919F/BgEcdO6mfRwhhn5wKTi1qnIs5hEdeUCvv8KRHsp6g88WHgA3e/t4h1jonWw8y6EM5zsYPplWN8h5pZ7fznhErF9wqsNhW42IKuwIaEW9CKUuS3sGSevwISx8IaCPyzkHVmAD80s7pR0ccPo2WxMrOewE1AH3ffUsQ6pfksxBljYr3TOUUcuzRjksXpTGCJu+cV9mZFnMNirikV9/mLqyY8XR/AqYRbtEXAwujRCxgCDInWuRJYTGgB8QZwSgXG1yw67jtRDMOj5YnxGWH2uI+Ad4HsCj6HhxIu7IclLEvq+SMkpU+B7YRy1ksJc2O8DHwIvAQcEa2bDTyUsO0lwLLo8fMKim0ZoWw4/zP412jd44BpxX0WKvD8PRF9vhYRLmrHFowxet2L0FLmo7hiLCy+aPmj+Z+7hHUr9BwWc02psM+fhpgQEclwKhoSEclwSgQiIhlOiUBEJMMpEYiIZDglAhGRDKdEIBIxs52298io5TYSppk1SRz5UiSVxDpVpUgls9Xd2yc7CJGKpjsCkRJE49HfHY1J/5aZHR8tb2Jmr0SDqr1sZo2i5UdbmCPgnehxSrSrqmb2YDTm/Itmdki0/tXRWPSLzGxSkn5NyWBKBCJ7HFKgaOinCe9tcPc2wJ+BMdGyPwGPuXtbwqBvY6PlY4FXPQya15HQIxWgOTDO3VsB64GfRMuHAR2i/QyJ51cTKZp6FotEzGyzu9cqZPkK4PvuvjwaHOwzdz/SzL4kDJuwPVr+qbvXM7O1QJa7f5uwjyaEceObR69vBqq5+x1m9m9gM2GU1SkeDbgnUlF0RyBSOl7E8/3xbcLzneypo+tNGPupIzAvGhFTpMIoEYiUzk8Tfr4ePZ9LGC0TIAeYEz1/GRgKYGZVzeywonZqZlWAhu4+E7gZOAzY565EJE765iGyxyG29wTm/3b3/Cakdc1sEeFb/YBo2VXABDO7EVgL/Dxafg0w3swuJXzzH0oY+bIwVYEno2RhwFh3X19Ov49IqaiOQKQEUR1Btrt/mexYROKgoiERkQynOwIRkQynOwIRkQynRCAikuGUCEREMpwSgYhIhlMiEBHJcP8fcjugdY4Q7roAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4dfeb3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7ce09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = model1.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f6562eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model1.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0bfe810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e4e5304f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('콜린스', 0.6878893375396729),\n",
       " ('최정원', 0.6255038380622864),\n",
       " ('두렵', 0.620094895362854),\n",
       " ('..!', 0.6183009743690491),\n",
       " ('상하이', 0.6150099039077759),\n",
       " ('예쁜', 0.6108370423316956),\n",
       " ('잖', 0.6094949245452881),\n",
       " ('욤', 0.6094669103622437),\n",
       " ('어머니', 0.6081631183624268),\n",
       " ('왔었', 0.598190188407898)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"재밌\") # 형편없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "33c1e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getenv('HOME')+'/data/word2vec_ko.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67218784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb9bbe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = word_vectors.wv[\"끝\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "09f929a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b35cb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('재미있', 0.905171275138855),\n",
       " ('멋있', 0.8684316277503967),\n",
       " ('웃기', 0.8312839269638062),\n",
       " ('예쁘', 0.8087937235832214),\n",
       " ('슬프', 0.7751518487930298),\n",
       " ('무섭', 0.7676399350166321),\n",
       " ('재미없', 0.7673381567001343),\n",
       " ('멋지', 0.7514932155609131),\n",
       " ('신나', 0.7510867714881897),\n",
       " ('서툴', 0.7421588897705078)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.wv.most_similar('재밌') # 훌룡하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e94a3295",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_to_index)    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 100  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(3,vocab_size):\n",
    "    if index_to_word[i] in word_vectors.wv:\n",
    "        embedding_matrix[i] = word_vectors.wv[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bcd99617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 100)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9320c021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 42, 100)           2000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,085,521\n",
      "Trainable params: 2,085,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = len(word_to_index)   # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 100 # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=42, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7e6ac758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "235/235 [==============================] - 6s 14ms/step - loss: 0.4881 - accuracy: 0.7591 - val_loss: 0.3935 - val_accuracy: 0.8252\n",
      "Epoch 2/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.3555 - accuracy: 0.8445 - val_loss: 0.3466 - val_accuracy: 0.8478\n",
      "Epoch 3/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.3068 - accuracy: 0.8694 - val_loss: 0.3304 - val_accuracy: 0.8561\n",
      "Epoch 4/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.2731 - accuracy: 0.8864 - val_loss: 0.3252 - val_accuracy: 0.8611\n",
      "Epoch 5/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.2486 - accuracy: 0.8992 - val_loss: 0.3305 - val_accuracy: 0.8621\n",
      "Epoch 6/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.2252 - accuracy: 0.9099 - val_loss: 0.3356 - val_accuracy: 0.8615\n",
      "Epoch 7/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.2050 - accuracy: 0.9200 - val_loss: 0.3504 - val_accuracy: 0.8605\n",
      "Epoch 8/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.1863 - accuracy: 0.9289 - val_loss: 0.3766 - val_accuracy: 0.8524\n",
      "Epoch 9/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.1709 - accuracy: 0.9359 - val_loss: 0.3804 - val_accuracy: 0.8569\n",
      "Epoch 10/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.1527 - accuracy: 0.9442 - val_loss: 0.4076 - val_accuracy: 0.8570\n",
      "Epoch 11/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.1384 - accuracy: 0.9497 - val_loss: 0.4318 - val_accuracy: 0.8556\n",
      "Epoch 12/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.1258 - accuracy: 0.9557 - val_loss: 0.4681 - val_accuracy: 0.8546\n",
      "Epoch 13/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.1134 - accuracy: 0.9611 - val_loss: 0.4856 - val_accuracy: 0.8554\n",
      "Epoch 14/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.1013 - accuracy: 0.9661 - val_loss: 0.5252 - val_accuracy: 0.8505\n",
      "Epoch 15/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0911 - accuracy: 0.9697 - val_loss: 0.5466 - val_accuracy: 0.8498\n",
      "Epoch 16/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0822 - accuracy: 0.9736 - val_loss: 0.5974 - val_accuracy: 0.8487\n",
      "Epoch 17/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0757 - accuracy: 0.9752 - val_loss: 0.6129 - val_accuracy: 0.8478\n",
      "Epoch 18/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0667 - accuracy: 0.9786 - val_loss: 0.6546 - val_accuracy: 0.8479\n",
      "Epoch 19/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0616 - accuracy: 0.9804 - val_loss: 0.7110 - val_accuracy: 0.8479\n",
      "Epoch 20/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0564 - accuracy: 0.9821 - val_loss: 0.7201 - val_accuracy: 0.8459\n",
      "Epoch 21/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0504 - accuracy: 0.9838 - val_loss: 0.7884 - val_accuracy: 0.8456\n",
      "Epoch 22/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0483 - accuracy: 0.9845 - val_loss: 0.8122 - val_accuracy: 0.8438\n",
      "Epoch 23/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.8269 - val_accuracy: 0.8428\n",
      "Epoch 24/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0400 - accuracy: 0.9871 - val_loss: 0.8503 - val_accuracy: 0.8444\n",
      "Epoch 25/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0382 - accuracy: 0.9873 - val_loss: 0.8872 - val_accuracy: 0.8442\n",
      "Epoch 26/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0335 - accuracy: 0.9890 - val_loss: 0.9352 - val_accuracy: 0.8398\n",
      "Epoch 27/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0436 - accuracy: 0.9847 - val_loss: 0.9438 - val_accuracy: 0.8450\n",
      "Epoch 28/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0283 - accuracy: 0.9907 - val_loss: 1.0048 - val_accuracy: 0.8373\n",
      "Epoch 29/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0285 - accuracy: 0.9902 - val_loss: 1.0837 - val_accuracy: 0.8419\n",
      "Epoch 30/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0288 - accuracy: 0.9897 - val_loss: 1.0936 - val_accuracy: 0.8440\n",
      "Epoch 31/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0279 - accuracy: 0.9902 - val_loss: 1.1166 - val_accuracy: 0.8447\n",
      "Epoch 32/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0290 - accuracy: 0.9894 - val_loss: 1.1894 - val_accuracy: 0.8440\n",
      "Epoch 33/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0258 - accuracy: 0.9906 - val_loss: 1.1333 - val_accuracy: 0.8431\n",
      "Epoch 34/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0235 - accuracy: 0.9914 - val_loss: 1.1933 - val_accuracy: 0.8433\n",
      "Epoch 35/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0209 - accuracy: 0.9920 - val_loss: 1.2030 - val_accuracy: 0.8431\n",
      "Epoch 36/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0269 - accuracy: 0.9898 - val_loss: 1.2403 - val_accuracy: 0.8418\n",
      "Epoch 37/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0206 - accuracy: 0.9923 - val_loss: 1.2338 - val_accuracy: 0.8411\n",
      "Epoch 38/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0185 - accuracy: 0.9928 - val_loss: 1.2835 - val_accuracy: 0.8426\n",
      "Epoch 39/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0253 - accuracy: 0.9904 - val_loss: 1.2410 - val_accuracy: 0.8437\n",
      "Epoch 40/40\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0221 - accuracy: 0.9911 - val_loss: 1.2966 - val_accuracy: 0.8418\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'best_model.h5',             # 저장 파일명\n",
    "    monitor='val_loss',          # validation loss가 가장 좋은 모델만 저장\n",
    "    save_best_only=True,         # 가장 좋은 것만 저장\n",
    "    save_weights_only=False      # 전체 모델 저장 (구조 + 가중치)\n",
    ")\n",
    "              \n",
    "epochs=40  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5b7c9f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0b70c0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 - 5s - loss: 0.3344 - accuracy: 0.8563\n",
      "[0.3344214856624603, 0.8562913537025452]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
